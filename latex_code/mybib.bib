@ARTICLE{Serra_1986,title={Introduction to mathematical morphology},year={1986},author={Jean Serra},doi={10.1016/0734-189x(86)90002-2},pmid={null},pmcid={null},mag_id={2071238544},journal={Graphical Models \/graphical Models and Image Processing \/computer Vision, Graphics, and Image Processing},abstract={Transformations morphologiques, morphologie euclidienne, erosion et notions derivees, ouvertures et fermetures, amincissements et epaississements}}

@ARTICLE{Serra_1983,title={Image Analysis and Mathematical Morphology},year={1983},author={Jean Serra},doi={10.1002/cyto.990040213},pmid={null},pmcid={null},mag_id={2164741953},journal={Academic Press, London},abstract={null}}

@ARTICLE{Serra_1992,title={An overview of morphological filtering},year={1992},author={Jean Serra and Luc Vincent},doi={10.1007/bf01189221},pmid={null},pmcid={null},mag_id={2074113357},journal={Circuits Systems and Signal Processing},abstract={This paper consists of a tutorial overview of morphological filtering, a theory introduced in 1988 in the context of mathematical morphology. Its first section is devoted to the presentation of the lattice framework. Emphasis is put on the lattices of numerical functions in digital and continuous spaces. The basic filters, namely the openings and the closings, are then described and their various versions are listed. In the third section morphological filters are defined as increasing idempotent operators, and their laws of composition are proved. The last sections are concerned with two special classes of filters and their derivations: first, the alternating sequential filters allow us to bring into play families of operators depending on a positive scale parameter. Finally, the center and the toggle mappings modify the function under study by comparing it, at each point, with a few reference transforms.},volume={vol. 11},pages={47-108}}

@ARTICLE{Haralick_1987,title={Image Analysis Using Mathematical Morphology},year={1987},author={Robert M. Haralick and Stanley R. Sternberg and Xinhua Zhuang},doi={10.1109/tpami.1987.4767941},pmid={21869411},pmcid={null},mag_id={2154741421},journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},abstract={For the purposes of object or defect identification required in industrial vision applications, the operations of mathematical morphology are more useful than the convolution operations employed in signal processing because the morphological operators relate directly to shape. The tutorial provided in this paper reviews both binary morphology and gray scale morphology, covering the operations of dilation, erosion, opening, and closing and their relations. Examples are given for each morphological concept and explanations are given for many of their interrelationships.}}

@ARTICLE{Horgan_1998,title={Mathematical morphology for analysing soil structure from images},year={1998},author={Horgan},doi={10.1046/j.1365-2389.1998.00160.x},pmid={null},pmcid={null},mag_id={2114087994},journal={European Journal of Soil Science},abstract={Mathematical morphology is an approach to image analysis based on set theory. It explores structures by examining the effect of transforming them by set operations. Such operations can be built up and combined into powerful tools for exploring, transforming and measuring the size, shape and connectivity of components of interest in images. Greylevel images are handled by regarding them as binary images in three dimensions. This paper reviews the basic ideas and illustrates them by application to studies of the size distribution of soil pores, the lengths and geometric patterns of cracks in drying soil, and the growth of fungal hyphae. It then extends them in an introductory way to random sets. Practical issues of scale, resolution, sampling, replication and noise in the use of images for soil measurement are described briefly.},volume={vol. 49},pages={161-173}}

@ARTICLE{Peters_1995,title={A new algorithm for image noise reduction using mathematical morphology},year={1995},author={Ii. R.A. Peters},doi={10.1109/83.382491},pmid={18290006},pmcid={null},mag_id={2029091038},journal={IEEE Transactions on Image Processing},abstract={Morphological openings and closings are useful for the smoothing of gray-scale images. However, their use for image noise reduction is limited by their tendency to remove important, thin features from an image along with the noise. The paper presents a description and analysis of a new morphological image cleaning algorithm (MIC) that preserves thin features while removing noise. MIC is useful for gray-scale images corrupted by dense, low-amplitude, random, or patterned noise. Such noise is typical of scanned or still-video images. MIC differs from previous morphological noise filters in that it manipulates residual images-the differences between the original image and morphologically smoothed versions. It calculates residuals on a number of different scales via a morphological size distribution. It discards regions in the various residuals that it judges to contain noise. MIC creates a cleaned image by recombining the processed residual images with a smoothed version. The paper describes the MIC algorithm in detail, discusses the effects of parametric variations, presents the results of a noise analysis and shows a number of examples of its use, including the removal of scanner noise. It also demonstrates that MIC significantly improves the JPEG compression of a gray-scale image. >}}

@ARTICLE{Masci_2012,title={A Learning Framework for Morphological Operators using Counter-Harmonic Mean},year={2012},author={Jonathan Masci and Jesús Angulo and Jürgen Schmidhuber},doi={10.1007/978-3-642-38294-9_28},pmid={null},pmcid={null},mag_id={2950744532},journal={arXiv: Computer Vision and Pattern Recognition},abstract={We present a novel framework for learning morphological operators using counter-harmonic mean. It combines concepts from morphology and convolutional neural networks. A thorough experimental validation analyzes basic morphological operators dilation and erosion, opening and closing, as well as the much more complex top-hat transform, for which we report a real-world application from the steel industry. Using online learning and stochastic gradient descent, our system learns both the structuring element and the composition of operators. It scales well to large datasets and online settings.}}

@ARTICLE{Hermary_2022,title={Learning Grayscale Mathematical Morphology with Smooth Morphological Layers},year={2022},author={Romain Hermary and Guillaume Tochon and Élodie Puybareau and Alexandre Kirszenberg and Jesús Angulo},doi={10.1007/s10851-022-01091-1},pmid={null},pmcid={null},mag_id={4280624426},journal={Journal of Mathematical Imaging and Vision},abstract={The integration of mathematical morphology operations within convolutional neural network architectures has received an increasing attention lately. However, replacing standard convolution layers by morphological layers performing erosions or dilations is particularly challenging because the \\(\\min \\) and \\(\\max \\) operations are not differentiable. P-convolution layers were proposed as a possible solution to this issue since they can act as smooth differentiable approximation of \\(\\min \\) and \\(\\max \\) operations, yielding pseudo-dilation or pseudo-erosion layers. In a recent work, we proposed two novel morphological layers based on the same principle as the p-convolution, while circumventing its principal drawbacks, and showcased their capacity to efficiently learn grayscale morphological operators while raising several edge cases. In this work, we complete those previous results by thoroughly analyzing the behavior of the proposed layers and by investigating and settling the reported edge cases. We also demonstrate the compatibility of one of the proposed morphological layers with binary morphological frameworks.},volume={vol. 64},pages={736–753}}

@ARTICLE{Shih_2019,title={Development of Deep Learning Framework for Mathematical Morphology},year={2019},author={Frank Y. Shih and Yucong Shen and Xin Zhong},doi={10.1142/s0218001419540247},pmid={null},pmcid={null},mag_id={2897184471},journal={International Journal of Pattern Recognition and Artificial Intelligence},abstract={Mathematical morphology has been applied as a collection of nonlinear operations related to object features in images. In this paper, we present morphological layers in deep learning framework, nam...},volume={vol. 33},pages={1954024}}

@ARTICLE{Kirszenberg_2021,title={Going beyond p-convolutions to learn grayscale morphological operators},year={2021},author={Alexandre Kirszenberg and G. Tochon and É. Puybareau and J. Angulo},doi={10.1007/978-3-030-76657-3_34},pmid={null},pmcid={null},mag_id={null},journal={International Joint Conference on Discrete Geometry and Mathematical Morphology},abstract={null},pages={470-482}}

@ARTICLE{Keiller_2019,title={An Introduction to Deep Morphological Networks},year={2019},author={Nogueira, Keiller and Chanussot, Jocelyn and Mura, Mauro Dalla and Santos, Jefersson A. dos},doi={10.48550/arxiv.1906.01751},pmid={null},pmcid={null},mag_id={4288336433},journal={arXiv:1906.01751},abstract={The recent impressive results of deep learning-based methods on computer vision applications brought fresh air to the research and industrial community. This success is mainly due to the process that allows those methods to learn data-driven features, generally based upon linear operations. However, in some scenarios, such operations do not have a good performance because of their inherited process that blurs edges, losing notions of corners, borders, and geometry of objects. Overcoming this, non-linear operations, such as morphological ones, may preserve such properties of the objects, being preferable and even state-of-the-art in some applications. Encouraged by this, in this work, we propose a novel network, called Deep Morphological Network (DeepMorphNet), capable of doing non-linear morphological operations while performing the feature learning process by optimizing the structuring elements. The DeepMorphNets can be trained and optimized end-to-end using traditional existing techniques commonly employed in the training of deep learning approaches. A systematic evaluation of the proposed algorithm is conducted using two synthetic and two traditional image classification datasets. Results show that the proposed DeepMorphNets is a promising technique that can learn distinct features when compared to the ones learned by current deep learning methods.}}

@ARTICLE{Roy_2021,title={Morphological Convolutional Neural Networks for Hyperspectral Image Classification},year={2021},author={Swalpa Kumar Roy and Ranjan Mondal and Mercedes E. Paoletti and Juan M. Haut and Antonio Plaza},doi={10.1109/jstars.2021.3088228},pmid={null},pmcid={null},mag_id={3167109952},journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},abstract={Convolutional neural networks (CNNs) have become quite popular for solving many different tasks in remote sensing data processing. The convolution is a linear operation which extracts features from the input data. However, nonlinear operations are able to better characterize the internal relationships and hidden patterns within complex remote sensing data, such as hyperspectral images (HSIs). Morphological operations are powerful nonlinear transformations for feature extraction that preserve the essential characteristics of the image, such as borders, shape and structural information. In this paper, a new end-to-end morphological deep learning framework (called MorphConvHyperNet) is introduced. The proposed approach efficiently models nonlinear information during the training process of HSI classification. Specifically our method includes spectral and spatial morphological blocks to extract relevant features from the HSI input data. These morphological blocks consist of two basic 2D morphological operators (erosion and dilation) in the respective layers, followed by a weighted combination of the feature maps. Both layers can successfully encode the nonlinear information related to shape and size, playing an important role in classification performance. Our experimental results, obtained on two widely used HSIs, reveal that our newly proposed MorphConvHyperNet offers comparable (and even superior) performance when compared to traditional 2D and 3D CNNs for HSI classification. The source code is publicly available at https://github.com/mhaut/MorphConvHyperNet.},volume={vol. 14},pages={8689-8702}}

@ARTICLE{Angulo_2010,title={Pseudo-morphological Image Diffusion Using the Counter-Harmonic Paradigm},year={2010},author={Jesús Angulo},doi={10.1007/978-3-642-17688-3_40},pmid={null},pmcid={null},mag_id={1572959588},journal={Advanced Concepts for Intelligent Vision Systems Conference},abstract={Relationships between linear and morphological scale-spaces have been considered by various previous works. The aim of this paper is to study how to generalize the diffusion-based approaches in order to introduce nonlinear filters which effects mimic morphological dilation and erosion. A methodology based on the counter-harmonic mean is adopted here. Details of numerical implementation are discussed and results are provided to illustrate the behaviour of various studied cases: isotropic, nonlinear and coherence-enhanced diffusion. We also rediscover the classical link between Gaussian scale-space and dilation/erosion scale-spaces based on quadratic structuring functions.},pages={426-437}}

@ARTICLE{Bullen_1987,title={Handbook of means and their inequalities},year={2013},author={P. S. Bullen},doi={10.1007/978-94-017-0399-4},pmid={null},pmcid={null},mag_id={1523281138},journal={Springer, Berlin},abstract={- Preface to 'Means and their Inequalities'. Preface to the Handbook. Basic References. - Notations. 1. Referencing. 2. Bibliographic References. 3. Symbols for some Important Inequalities. 4. Numbers, Sets and Set Functions. 5. Intervals. 6. n-tuples. 7. Matrices. 8. Functions. 9. Various. A List of Symbols. An Introductory Survey. - I: Introduction. 1. Properties of Polynomials. 2. Elementary Inequalities. 3. Properties of Sequences. 4. Convex Functions. - II: The Arithmetic, Geometric and Harmonic Means. 1. Definitions and Simple Properties. 2. The Geometric Mean-Arithmetic Mean Inequality. 3. Refinements of the Geometric Mean-Arithmetic Mean Inequality. 4. Converse Inequalities. 5. Some Miscellaneous Results. - III: The Power Means. 1. Definitions and Simple Properties. 2. Sums of Powers. 3. Inequalities between the Power Means. 4. Converse Inequalities. 5. Other Means Defined Using Powers. 6. Some Other Results. - IV: Quasi-Arithmetic Means. 1. Definitions and Basic Properties. 2. Comparable Means and Functions. 3. Results of Rado Popoviciu Type. 4. Further Inequalities. 5. Generalizations of the Holder and Minkowski Inequalities. 6. Converse Inequalities. 7. Generalizations of the Quasi-arithmetic Means. - V: Symmetric Polynomial Means. 1. Elementary Symmetric Polynomials and Their Means. 2. The Fundamental Inequalities. 3.Extensions of S(r s) of Rado Popoviciu Type. 4. The Inequalities of Marcus and Lopes. 5. Complete Symmetric Polynomial Means: Whiteley Means. 6. The Muirhead Means. 7. Further Generalizations. - VI: Other Topics. 1. Integral Means and Their Inequalities. 2. Two Variable Means. 3. Compounding of Means. 4. Some General Approaches to Means. 5. Mean Inequalities for Matrices. 6. Axiomatization of Means. Bibliography. Name Index. Index.},volume={vol. 560}}

@ARTICLE{Bloch_2021,title={On Some Associations Between Mathematical Morphology and Artificial Intelligence.},year={2021},author={Isabelle Bloch and Samy Blusseau and Ramón Pino Pérez and Élodie Puybareau and Guillaume Tochon},doi={10.1007/978-3-030-76657-3_33},pmid={null},pmcid={null},mag_id={3160553025},journal={International Joint Conference on Discrete Geometry and Mathematical Morphology},abstract={This paper aims at providing an overview of the use of mathematical morphology, in its algebraic setting, in several fields of artificial intelligence (AI). Three domains of AI will be covered. In the first domain, mathematical morphology operators will be expressed in some logics (propositional, modal, description logics) to answer typical questions in knowledge representation and reasoning, such as revision, fusion, explanatory relations, satisfying usual postulates. In the second domain, spatial reasoning will benefit from spatial relations modeled using fuzzy sets and morphological operators, with applications in model-based image understanding. In the third domain, interactions between mathematical morphology and deep learning will be detailed. Morphological neural networks were introduced as an alternative to classical architectures, yielding a new geometry in decision surfaces. Deep networks were also trained to learn morphological operators and pipelines, and morphological algorithms were used as companion tools to machine learning, for pre/post processing or even regularization purposes. These ideas have known a large resurgence in the last few years and new ones are emerging.},pages={457-469}}

@ARTICLE{Wilson_1989,title={Morphological Networks},year={1989},author={Stephen S. and Wilson},doi={10.1117/12.970058},pmid={null},pmcid={null},mag_id={2339923884},journal={Visual Communications and Image Processing IV},abstract={The standard operations in mathematical morphology involve erosions, dilations, openings, and closings which have been defined on binary and grey scale images. A generalization of standard morphology is discussed and leads to a new operation: weighted rank order filters. A different type of generalization leads to morphology in a vector space. A combination of the two ideas is developed, and involves a sequence or network of layers of weighted rank order filters on vector spaces which have properties very similar to multi-layer neural networks. A weighted rank order cell has a non-linear soft threshold response at the output. Due to the nature of rank order filtering, a unique supervised training procedure can be defined which allows weights in hidden layers to be trained as quickly and easily as those in the output layer.},volume={vol. 1199},pages={483-495}}

@ARTICLE{Davidson_1990,title={Theory of morphological neural networks},year={1990},author={Jennifer L. Davidson and Gerhard X. Ritter},doi={10.1117/12.18085},pmid={null},pmcid={null},mag_id={2073074703},journal={Photonics West - Lasers and Applications in Science and Engineering},abstract={The theory of classical artificial neural networks has been used to solve pattern recognition problems in image processing that is different from traditional pattern recognition approaches. In standard neural network theory, the first step in performing a neural network calculation involves the linear operation of multiplying neural values by their synaptic strengths and adding the results. Thresholding usually follows the linear operation in order to provide for non-linearity of the network. This paper presents the fundamental theory for a morphological neural network which, instead of multiplication and summation, uses the non-linear operation of addition and maximum. Several basic applications which are distinctly different from pattern recognition techniques are given, including a net which performs a sieving algorithm.© (1990) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.},pages={378-388}}

@ARTICLE{LeCun_2015,title={Deep learning},year={2015},author={Yann LeCun and Yoshua Bengio and Geoffrey E. Hinton},doi={10.1038/nature14539},pmid={26017442},pmcid={null},mag_id={2919115771},journal={Nature},abstract={Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},volume={vol. 521},pages={436-444}}

@ARTICLE{Hassoun_1996,title={Fundamentals of Artificial Neural Networks},year={1996},author={Mohamad H. Hassoun and Nathan Intrator and Susan McKay and Wolfgang Christian},doi={10.1063/1.4822376},pmid={null},pmcid={null},mag_id={1975891294},journal={Computers in Physics},abstract={From the Publisher: As book review editor of the IEEE Transactions on Neural Networks, Mohamad Hassoun has had the opportunity to assess the multitude of books on artificial neural networks that have appeared in recent years. Now, in Fundamentals of Artificial Neural Networks, he provides the first systematic account of artificial neural network paradigms by identifying clearly the fundamental concepts and major methodologies underlying most of the current theory and practice employed by neural network researchers. Such a systematic and unified treatment, although sadly lacking in most recent texts on neural networks, makes the subject more accessible to students and practitioners. Here, important results are integrated in order to more fully explain a wide range of existing empirical observations and commonly used heuristics. There are numerous illustrative examples, over 200 end-of-chapter analytical and computer-based problems that will aid in the development of neural network analysis and design skills, and a bibliography of nearly 700 references. Proceeding in a clear and logical fashion, the first two chapters present the basic building blocks and concepts of artificial neural networks and analyze the computational capabilities of the basic network architectures involved. Supervised, reinforcement, and unsupervised learning rules in simple nets are brought together in a common framework in chapter three. The convergence and solution properties of these learning rules are then treated mathematically in chapter four, using the "average learning equation" analysis approach. This organization of material makes it natural to switch into learning multilayer nets using backpropand its variants, described in chapter five. Chapter six covers most of the major neural network paradigms, while associative memories and energy minimizing nets are given detailed coverage in the next chapter. The final chapter takes up Boltzmann machines and Boltzmann learning along with other global search/optimization algorithms such as stochastic gradient search, simulated annealing, and genetic algorithms.},volume={vol. 10},pages={137}}

@ARTICLE{Lange_2014,title={Applications of lp-Norms and their Smooth Approximations for Gradient Based Learning Vector Quantization.},year={2014},author={Mandy Lange and Dietlind Zühlke and Olaf Holz and Thomas Villmann},doi={null},pmid={null},pmcid={null},mag_id={2400652284},journal={The European Symposium on Artificial Neural Networks},abstract={Learning vector quantization applying non-standard metrics became quite popular for classification performance improvement compared to standard approaches using the Euclidean distance. Kernel metrics and quadratic forms belong to the most promising approaches. In this paper we consider Minkowski distances (lp-norms). In particular, l1-norms are known to be robust against noise in data, such that, if this structural knowledge is available in advance about the data, this norm should be utilized. However, application in gradient based learning algorithms based on distance evaluations need to calculate the respective derivatives. Because lp-distance formulas contain the absolute approximations thereof are required. We consider in this paper several approaches for smooth consistent approximations for numerical evaluations and demonstrate the applicability for exemplary real world applications.},pages={271-276}}

@ARTICLE{LeCun_2005,title={The MNIST database of handwritten digits},year={1998},author={Yann LeCun and Corinna Cortes},doi={null},pmid={null},pmcid={null},mag_id={200806003},journal={http://yann.lecun.com/exdb/mnist},abstract={Disclosed is an improved articulated bar flail having shearing edges for efficiently shredding materials. An improved shredder cylinder is disclosed with a plurality of these flails circumferentially spaced and pivotally attached to the periphery of a rotatable shaft. Also disclosed is an improved shredder apparatus which has a pair of these shredder cylinders mounted to rotate about spaced parallel axes which cooperates with a conveyer apparatus which has a pair of inclined converging conveyer belts with one of the belts mounted to move with respect to the other belt to allow the transport of articles of various sizes therethrough.}}
